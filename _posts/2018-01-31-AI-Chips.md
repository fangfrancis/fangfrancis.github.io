---
layout: post
title: AI 芯片回顾与展望
category: AI
tags: Technology, Hardware, Software, AI
---

| 传统芯片巨头 | 互联网/云计算   | 芯片初创企业(中国)      | 芯片初创企业(全球)                 |
| ------ | --------- | --------------- | -------------------------- |
| Nvidia | Google    | 寒武纪，A 轮 1 亿美元   | Graphcore，3 轮 1.1 亿美元      |
| Intel  | AWS/Azure | 地平线，A+ 轮 1 亿美元  | Wave Computing，4 轮 1.2 亿美元 |
| AMD    | BAT       | 深鉴科技，A 轮 4 千万美元 | Cerebras，2 轮 5.2 千万美元      |
| 海思     | 华为        | 比特大陆，A 轮 5 千万美元 | Groq，天使轮 1 千万美元            |
| …      | …         | …               | …                          |

*注：1）融资数据来源：Crunchbase；2）根据公开信息，除 Google 外的互联网/云计算服务商目前仍采用 FPGA 加速*

  

## **2017——AI芯片元年**

随着摩尔定律趋于失效，半导体行业正在从之前追求的 More Moore（进一步缩小晶体管尺寸）转向为 More than Moore（针对不同的应用开发专用半导体电路）以及 Beyond Moore（研发新的器件和计算范式）。其中，More than Moore 以及相应的「应用驱动」将是未来几年的重点方向。

### **Google vs. Nvidia**

AI 芯片是 2017 年半导体行业的亮点，其主旋律是 Google 和 Nvidia 的缠斗。

- 4月，Google 在 ISCA2017 上公布了 TPU 论文，披露了若干细节，引起了半导体及互联网行业的极大关注。
- 5月，Nvidia 于 GTC 大会上发布了最新的 GPU Volta 架构，并宣布开源 Deep Learning Accelerator（DLA），其开源的内容及意图一直众说纷纭，毕竟 Training 才是其核心利益所在。
- 同月，Google 在其 I/O 大会上公布了 TPU 2，同时支持 Training 和 Inference，且具有很好的性能和可扩展性，但只以 TPU Cloud 的方式对外开放。
- 9 月的 HotChips 大会，Google 的 Jeff Dean 亲自介绍了 TPU 和 TPU2 及其代表的新计算生态。
- 同月，Nvidia 的 DLA 在承诺的最后期限前开源了部分硬件代码，以及未来的开源路线图。由于离真正使用还有较大差距，所以目前看来并没有影响各 AI 芯片初创企业的融资。
- 10月，Google 公布其 Pixel 2 手机中使用了定制 SoC IPU。

这场贯穿全年的战争，对业界的影响力远远超过两家公司本身，**Google 引领了科技巨头加入 AI 加速硬件竞争的趋势**，如 12 月 Tesla 宣布正在研发用于自动驾驶的 AI 芯片，相信这一趋势随着时间的推移会愈发明显。

### **传统巨头 vs. 初创企业**

传统巨头不会坐以待毙，Intel 通过连续收购完善布局，试图后发制人；AMD 也在努力追赶，并传言正与 Tesla 合作自动驾驶芯片。初创企业也毫不逊色，全球范围内的 AI 芯片初创公司据传已超过 100 家，在 TSMC 排队投片的也已达 30 家。

**传统上，投资者往往不愿意投芯片创业企业，但现在资本却对 AI 芯片趋之若鹜。**国内外都出现了一批「头部企业」，国内如寒武纪、地平线、深鉴科技和比特大陆，都陆续发布了自己的产品；国外如 Graphcore、Wave Computing、Cerebras 和 Groq，则背景深厚且技术路线独具特色。但多数公司并没有公开具体信息，这也给了2018 年更多的期待。

  

## **2018——趋势预测与展望**

### **市场：从云到端**

AI的「应用驱动」，意味着创新的重点从云扩展到端/边缘，将导致芯片市场分裂为成千上万的细分市场，且它们对于成本和工艺的衡量策略完全不同。如果说 2017 年的看点是各种芯片的性能和功耗数据，那么 2018 年的看点则是应用的落地情况。

深度学习目前最能落地商用的方向是图像和语音识别，部署规模能达到千万级的主流终端市场，目前能看到的有：个人（手机&平板，约 30 亿颗）、安防（监控，亿级）、家居（家庭网关&电视盒子，7 亿颗；音箱，千万级但快速增长中）、机器人&无人机（各数百万，合计千万级）、汽车（ADAS 全球渗透率不到 10%，但快速增长中）。

### **技术：ISSCC 风向标**

从 ISSCC 这一半导体领域的顶级会议中我们可以一窥行业的大趋势。2018 年有两个以「Machine Learning」命名的 Session，其中一个是新增的「Computation in Memory for Machine Learning」，并行计算无需依靠处理器，在存储器中就能实现，摆脱了冯·诺伊曼架构下处理器与存储器的带宽限制。

而在「Machine Learning and Signal Processing」中，呈现出多数芯片都支持低精度，特别是二进制神经网络（BNN）的重大变化。BNN 的计算电路极其简单，带宽要求也不高，因此能达到 50TOPS/W 量级以上的性能。虽然实际应用是否能接受 BNN 并非由芯片设计者决定，但随着算法领域的不断突破，BNN 的应用将愈发广泛。

### **行业格局：从框架之争到 IR 之争**

芯片之争的关键不在于架构，而在于软硬件生态。Google 目前是生态最完整的企业，并试图以 TPU+Cloud+Tensorflow 不断巩固领先地位。Nvidia 在深度学习领域的成功，也离不开完善的 CUDA 生态。客户的需求是一套完整好用的解决方案，而框架是其中的核心。

不过深度学习还有个现实的问题，当前存在着大量不同的前端框架和后端硬件，需要找到一种方式更有效地实现它们之间的优化与映射。类似的场景其实在软件领域曾出现过，LLVM 的出现让不同的前后端使用统一的 IR（Intermediate Representation），可以很方便地扩展支持新的编程语言和硬件平台。

深度学习领域也需要类似的项目。目前，Tensorflow XLA、NNVM+TVM、ONNX 是这一领域主要的几个探索。不同的是，XLA 只针对 Tensorflow 优化，NNVM+TVM 隶属于 MXNet 阵营，但试图打造一个开放的接口，而 Facebook 发起的 ONNX 则是这一领域最新的尝试，希望以此与 Google Tensorflow 相抗衡。IR 之争，将是未来框架之争的要点。

### **几大看点：可能导致行业变局**

1. 传统芯片巨头，Nvidia 是否会推出专用加速芯片？Intel 的 Nervana 架构是否会重新定义市场？除了 Intel+AMD 以抗衡 Nvidia，是否还会有更多巨头间的合纵连横？

2. 芯片初创企业，面临「小考」，理论指标将会被实际性能取代，Graphcore 等国外初创企业能否拿出值得期待的产品？在 Edge 端有优势的 ARM 是否会有影响初创企业的大动作？

3. 互联网巨头，谁会步 Google 后尘自研芯片？

4. IR 之争，是 Tensorflow XLA 扩大领先，还是 NNVM+TVM、ONNX 能分庭抗礼？

5. 算法，BNN 能否得到广泛应用？深度学习之外的其他算法能否有巨大突破？

6. CPU 漏洞门，对 AI 云计算的影响程度？Google 和 Nvidia 是否会因此受益？