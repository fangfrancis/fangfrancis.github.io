---
layout: post
title: 机读世界
category: Trends
tags: Machine, Human, AI
---

关于未来，之前写过被**数字化**高度解析化的全新社会，即[「微粒社会」](https://fangfrancis.github.io/trends/2018/02/14/Granular-Society/)。

今天写写我们是如何迈入数字化的，原因之一是不断增加的**机器感知**，造就了「机读世界」。

![Sensor](/images/sensor.jpeg)

（题图来自 [Aspire Ventures](https://medium.com/aspire-ventures/building-the-bigger-picture-how-we-can-use-sensor-fusion-to-change-healthcare-81a1bcdb756a)）



## **1 过去只有机器可读，将来也只有机器可读**

### **1.1 传统的机读世界** 

```markdown
过去：机器（可读），人类（不可读）

趋势：机器（可读），人类（不可读）
```

这是指超越人类感知能力范围的一系列「信号」，比如红外、紫外、射电、超声波等等。

这是一系列只有机器可「读」的世界。

随着人类对世界理解的增强，我们设计了新的工具和新的方式，机器的感知能力也在不断加强。



### **1.2 新的信号，服务于范围从人扩展到机器**

```markdown
过去：机器（可读），人类（不可读），但服务于人类场景

趋势：机器（可读），人类（不可读），为机器场景提供单独的信号

提升层面：信号
```

**例子1：**5G，uRLLC/mMTC 两大应用场景

移动通信从 1G 到 4G 时代，通信信号一直服务于「人」，围绕「手机」的应用场景展开。而到了 5G 时代，则细分出了 eMBB/uRLLC/mMTC 的多样化场景，除了 eMBB 依旧围绕于人，uRLLC 和 mMTC 场景则更多服务于「物」的连接。

![5G](/images/5G.png)

**例子2：**高精地图，实现自动驾驶的关键

严格说来，手机里的地图也只有计算机能读，只不过地图软件（百度地图/Google Maps等）将其转换成了人类可以理解并交互的形式，并将地图扩展成了平台级产品。

而高精地图拥有精确的车辆位置信息和丰富的道路元素数据信息，起到构建类似于人脑对于空间的整体记忆与认知的功能，可以帮助汽车预知路面复杂信息，如坡度、曲率、航向等，更好地规避潜在的风险。

![HD Maps](/images/HD-maps.jpg)



## **2 过去机器和人均不可读，将来机器可读**

### **2.1 新的感知方式，带来新的感知能力**

```markdown
过去：机器（不可读），人类（不可读）

趋势：机器（可读），人类（不可读）

提升层面：感知方式
```

**例子5：** ETH，「拍摄」黑洞

ETH（Event Horizon Telescope，事件视界望远镜）的天文学家通过遍布全球的阵列望远镜，形成了一个与地球本身大小相同的 VLBI （超长基线干涉仪），「拍摄」（**计算**）出了第一张黑洞的照片。不仅要得益于分布式天文台的模式创新，也需要感谢超算的**算力**支持。

![Event Horizon Telescope](/images/ETH_blackhole.jpg)



### **2.2 新的传感器，带来新的感知维度**

```markdown
过去：机器（不可读），人类（不可读）

趋势：机器（可读），人类（不可读）

提升层面：传感器
```

**例子3：**iPhone X，3D 感知技术

为 FaceID 功能而设计，基于 Kinect 的深度感应技术，iPhone X 的 True Depth 相机会扫描超过 3 万个不可见的点，形成完整的 3D 扫描。

![isensors](/images/isensors.jpg)

![facething](/images/facething.jpg)

**例子4：**Google Pixel 4，手势交互

将使用 Google 研究了多年的 Project Soli 技术，基于微型毫米波雷达来对手势进行监测，并将收录回来的雷达信号进行一系列的处理，并最终识别成各种交互手势，可以做到识别指尖级别的细微动作，如点按按钮、转动旋钮、拨动滑竿等。

![Soli_Pixel_4_Sensor.max-1000x1000](/images/Soli_Pixel_4_Sensor.max-1000x1000.png)

![radar visualisation loop](/images/radar-visualisation-loop.gif)




## **3 过去只有人可读，将来机器可读得更好**

正如在[《价值观载入问题》](https://fangfrancis.github.io/ai/2019/08/07/Value-Loading-Problem/)一文中提到的，「对人类很简单的事情，对机器可能极为复杂。而且这种复杂对于人类透明，在我们的生活中习以为常，往往意识不到它们的存在，如人类视觉 vs 计算机视觉。」

### **3.1 新的算法，带来新的感知能力**

```markdown
过去：机器（不可读），人类（可读），人类经过进化和自然选择而拥有的能力

趋势：机器（可读），人类（可读），且机器在感知能力赶上或超过了人类

提升层面：算法
```
在机器学习/深度学习等方法的不断发展和突破下，当前机器在**感知**世界方面的能力已经接近甚至超过人类。

特别是在计算机视觉和听觉的角度，驱动了数字世界与现实世界相连，具有极大的商业价值，也是目前 AI 商业化落地最主要的两个领域。

**例子6：**计算机视觉，2012 年以来，研究人员利用深度神经网络从根本上提高了机器对图像中物体的识别和分类能力，神经网络在多个领域已超越了人类的能力。

![Computer Vision](/images/Computer-Vision.png)



### **3.2 新的传感器，带来新的感知维度**

```markdown
过去：机器（不可读），人类（可读）

趋势：机器（可读），人类（可读），且机器感知了更丰富的信息

提升层面：传感器
```

**这是一种容易被忽视的场景：**同样的设备（如镜头、交通信号灯等），过去主要服务于人，但将来将更多服务于机器，信息可被读取维度更丰富。

**例子7：**光电镜头，用到更全面的光信息

Coherent.ai 的全息全频机器视觉，用光电技术改善计算机视觉整体效果。 光是电磁波的一种 ，波长在几百纳米的电磁波有很多的物理量，如频率、相位、光强、光谱、偏振、方向等，**普通传感器记录红绿蓝三种光强，其他信息丢掉了，这是对信息的浪费**。 把 AI 算法和光电微纳结构相结合 ，可以形成光电人工智能的芯片。

![light](/images/light.jpeg)

![coherent.ai](/images/coherent.ai.jpeg)

**例子8：**V2I，Vehicle 和 Infrastructure 间的信息交互

红绿灯的识别，将有助于自动驾驶的实现，除了依靠计算机视觉来攻克外，通过汽车与基础设施之间的信息交互，也是一种很好的信息辅助，起到「千里眼」、「透视镜」和「安全员」的作用。

![V2I](/images/V2I.jpg)



## 4 小结

![machine_vs_human](/images/machine_vs_human.png)

IoT、自动驾驶、自主体系、普适计算……随着未来机器的数量不断增多，其感知世界的需求会不断增强。

人类的感知能力毕竟是有限的，机器能够帮助我们更好的感知这个世界，将来还会帮助我们更好的认知这个世界。

不论是信号、算法、传感器，还是感知方式层面，都有很多的创新机会。特别是更多的传感器，意味着将促成更多的交互手段。

历史上，iPhone 的每次升级，除了UI、CPU、内存等，Apple 都在默默升级着「传感器」。最新的 iPhone X 的「刘海」只不过是为再一次「领先业界 5 年」所作的妥协，因为它需要承载「未来的交互」。

最后，如果传感器是整合一切输入的「新搜索」，那么整合所有传感器信息的「新 OS」会是什么？